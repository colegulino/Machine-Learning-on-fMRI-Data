{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from sklearn import decomposition\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, SelectPercentile\n",
    "from sklearn import linear_model\n",
    "from sklearn import cross_validation\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Import your data \n",
    "'''\n",
    "# Load the .mat files\n",
    "events_1000 = sio.loadmat('Data/events_1000.mat')\n",
    "missIdx = sio.loadmat('Data/missIdx.mat')\n",
    "provideData_1000 = sio.loadmat('Data/provideData_1000.mat')\n",
    "provideIdx = sio.loadmat('Data/provideIdx.mat')\n",
    "trainData = sio.loadmat('Data/Train.mat')\n",
    "testData = sio.loadmat('Data/Test.mat')\n",
    "yTest = sio.loadmat('Data/Ytest.mat')\n",
    "# \n",
    "events = events_1000.get('events')\n",
    "missidx = missIdx.get('missIdx')\n",
    "provideData = provideData_1000.get('provideData')\n",
    "provideidx = provideIdx.get('provideIdx')\n",
    "\n",
    "Xtrain = trainData.get('Xtrain')\n",
    "Ytrain = trainData.get('Ytrain')\n",
    "Yt2 = yTest.get('Ytest')\n",
    "Xtest = testData.get('Xtest')\n",
    "missingData = np.genfromtxt ('Data/prediction.csv', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Get unlabeled training data\n",
    "'''\n",
    "# Preallocate size of unlabeled data\n",
    "X2 = np.zeros((1000, 5903))\n",
    "# Get fully construct unlabeled data\n",
    "# Do missing data first\n",
    "i = 0\n",
    "for index in xrange(0, np.shape(missidx)[1]):\n",
    "    #print missidx[0][index]\n",
    "    X2[:, missidx[0][index]-1] = missingData[:,i]\n",
    "    i = i + 1\n",
    "# Now do for provided data\n",
    "i = 0\n",
    "for index in xrange(0, np.shape(provideidx)[1]):\n",
    "    X2[:, provideidx[0][index]-1] = provideData[:, i]\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:\n",
      "(1501, 5903)\n",
      "Y shape:\n",
      "(1501, 1)\n"
     ]
    }
   ],
   "source": [
    "# Add this data to the training data from part 1\n",
    "X = np.vstack((Xtrain, X2))\n",
    "\n",
    "# Get the Y for the semi-supervised learning\n",
    "Y = np.zeros((1501,1))\n",
    "Y[:501,:] = Ytrain\n",
    "Y[501:,:] = -1\n",
    "print \"X shape:\"\n",
    "print np.shape(X)\n",
    "print \"Y shape:\"\n",
    "print np.shape(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Setup Label Propogation - RBF or KNN\n",
    "'''\n",
    "# Parameters\n",
    "kernel_ = 'knn'\n",
    "gamma_ = 0.0001\n",
    "alpha_ = 0.2\n",
    "n_neighbors_ = 7\n",
    "tol_ = 0.001\n",
    "clf = LabelPropagation(kernel=kernel_, gamma=gamma_,\n",
    "                       alpha=alpha_, n_neighbors=n_neighbors_,\n",
    "                       tol=tol_)\n",
    "# Train the Classifier\n",
    "Xscale = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True).fit_transform(X)\n",
    "pca = decomposition.PCA(n_components=420)\n",
    "Xpca = pca.fit_transform(Xscale)\n",
    "clf.fit(Xpca, np.ravel(Y))\n",
    "# Get the new Y data\n",
    "X2scale = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True).fit_transform(X2)\n",
    "X2pca = pca.transform(X2scale)\n",
    "Y2 = clf.predict(X2pca)\n",
    "# Add these to the Y values\n",
    "Y[501:,:] = Y2[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816815837429\n",
      "0.620828300551"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Use the full data on the classification problem\n",
    "'''\n",
    "selection = SelectKBest(k=180)\n",
    "X_pca = selection.fit(Xpca, np.ravel(Y)).transform(Xpca)\n",
    "\n",
    "svm = SVC(C = 10, cache_size=200, coef0=0.0, gamma = 0.0001,\n",
    "          degree=3, kernel='rbf', max_iter=-1,\n",
    "          probability=True,random_state=None, shrinking=True, \n",
    "          tol=0.0001, verbose=False)\n",
    "\n",
    "svm.fit(X_pca, np.ravel(Y))\n",
    "scores = cross_validation.cross_val_score(clf, X_pca, np.ravel(Y), cv=10)\n",
    "print scores.mean()\n",
    "svm2 = SVC(C = 10, cache_size=200, coef0=0.0, gamma = 0.0001,\n",
    "          degree=3, kernel='rbf', max_iter=-1,\n",
    "          probability=True,random_state=None, shrinking=True, \n",
    "          tol=0.0001, verbose=False)\n",
    "Xscale = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True).fit_transform(Xtrain)\n",
    "pca = decomposition.PCA(n_components=420)\n",
    "Xpca = pca.fit_transform(Xscale)\n",
    "svm2.fit(Xtrain, np.ravel(Ytrain))\n",
    "scores2 = cross_validation.cross_val_score(svm2, Xpca, np.ravel(Ytrain), cv=10)\n",
    "print scores2.mean()\n",
    "plt.figure()\n",
    "plt.plot(scores, label='Part 3')\n",
    "plt.plot(scores2, label='Part 1')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Cross-Validation Score')\n",
    "plt.title('Cross-Validation Scores for Part 1 and Part 3')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = label_binarize(Y, classes=[0, 1, 3])\n",
    "n_samples, n_features = X.shape\n",
    "random_state = np.random.RandomState(0)\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "classifier = OneVsRestClassifier(SVC(kernel='rbf', probability=True,\n",
    "                                  gamma=0.0001,C=10, tol=0.0001))\n",
    "classifier.fit(X_pca, np.ravel(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "XTscale = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True).fit_transform(Xtest)\n",
    "XTpca = pca.transform(XTscale)\n",
    "X_Tpca = selection.transform(XTpca)\n",
    "y_score = classifier.decision_function(X_Tpca)\n",
    "y_test = classifier.predict(X_Tpca)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Plot of a ROC curve for a specific class\n",
    "plt.figure()\n",
    "plt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "# Plot ROC curves for the multiclass problem\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         linewidth=2)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         linewidth=2)\n",
    "\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "                                   ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Predict on old testX\n",
    "'''\n",
    "# Predict Y values\n",
    "XTscale = preprocessing.StandardScaler(copy=True, with_mean=True, with_std=True).fit_transform(Xtest)\n",
    "XTpca = pca.transform(XTscale)\n",
    "X_Tpca = selection.transform(XTpca)\n",
    "Ytest = svm.predict(X_Tpca)\n",
    "print Ytest\n",
    "# See accuracy on test set\n",
    "count = 0\n",
    "for i in xrange(0, np.shape(Ytest)[0]):\n",
    "    if(Ytest[i] == Yt2[i][0]):\n",
    "        count = count + 1\n",
    "print ((float(count) / 1000) *  100), \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
